# -*- coding: utf-8 -*-
"""EmotnRecognModel

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Izwuo40EpPC9NVHg1luSqSPvdvyLMPJ6
"""

import os
import librosa
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout

DATASET_PATH = "audio_speech_emotion_dataset/"

emotion_map = {
    "03": "happy",
    "04": "sad",
    "05": "angry"
}
target_emotions = set(emotion_map.values())

def extract_features(file_path):
    audio, sample_rate = librosa.load(file_path, duration=3, offset=0.5)
    mfcc = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)
    return np.mean(mfcc.T, axis=0)

features = []
emotions = []

for folder in os.listdir(DATASET_PATH):
    folder_path = os.path.join(DATASET_PATH, folder)
    if os.path.isdir(folder_path):
        for file in os.listdir(folder_path):
            if file.endswith(".wav"):
                parts = file.split("-")
                emotion_code = parts[2]
                emotion = emotion_map.get(emotion_code)
                if emotion in target_emotions:
                    try:
                        feature = extract_features(os.path.join(folder_path, file))
                        features.append(feature)
                        emotions.append(emotion)
                    except Exception as e:
                        print(f"Error processing {file}: {e}")

print(f"âœ… Extracted features from {len(features)} files.")

X = np.array(features)
le = LabelEncoder()
y = to_categorical(le.fit_transform(emotions))

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = Sequential()
model.add(Dense(256, input_shape=(40,), activation='relu'))
model.add(Dropout(0.3))
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.3))
model.add(Dense(y.shape[1], activation='softmax'))

model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

model.fit(X_train, y_train, epochs=50, batch_size=8, validation_data=(X_test, y_test))

loss, accuracy = model.evaluate(X_test, y_test)
print(f"\nðŸŽ¯ Test Accuracy: {accuracy * 100:.2f}%")

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import seaborn as sns
import matplotlib.pyplot as plt

# Predict labels for the test set
y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true_classes = np.argmax(y_test, axis=1)

# Generate the confusion matrix
cm = confusion_matrix(y_true_classes, y_pred_classes)

# Plot the confusion matrix
plt.figure(figsize=(8,6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=le.classes_, yticklabels=le.classes_)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

import os

DATASET_PATH = "audio_speech_emotion_dataset/"
count = 0
for folder in os.listdir(DATASET_PATH):
    folder_path = os.path.join(DATASET_PATH, folder)
    if os.path.isdir(folder_path):
        for file in os.listdir(folder_path):
            if file.endswith(".wav"):
                count += 1
print(f"Found {count} .wav files")

from google.colab import files
uploaded = files.upload()

import zipfile
import os

with zipfile.ZipFile("Actor_01.zip", 'r') as zip_ref:
    zip_ref.extractall("audio_speech_emotion_dataset")

print("Files in extracted folder:", os.listdir("audio_speech_emotion_dataset"))

DATASET_PATH = "audio_speech_emotion_dataset/"